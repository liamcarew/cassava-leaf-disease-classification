{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workspace Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries/packages here\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from deepforest import CascadeForestClassifier\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add GPU to list of devices, and configure so that memory usage can be tracked\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "print(gpu_devices)\n",
    "\n",
    "#Reset memory usage measurements\n",
    "for gpu in gpu_devices:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "#check that memory measurement variables have been reset\n",
    "if gpu_devices:\n",
    "  print(tf.config.experimental.get_memory_info('GPU:0'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's read in the dataset using the 'tensorflow-datasets' package. This package reads in the dataset and then converts it into TFRecords which contain the serialised image and the image label, as well as the data split the image belongs to: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in cassava dataset\n",
    "dataset, info = tfds.load('cassava', with_info=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the number of training, validation and test images imported is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training images: {}'.format(len(dataset['train'])))\n",
    "print('Validation images: {}'.format(len(dataset['validation'])))\n",
    "print('Test images: {}'.format(len(dataset['test'])))\n",
    "\n",
    "#all good"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image pre-processing:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin this section, let's define a function that performs pixel normalisation and image resizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to perform image resizing and pixel value normalisation\n",
    "def image_preprocessing(obs):\n",
    "\n",
    "  #normalise pixel values\n",
    "  obs['image'] = tf.cast(obs['image'], tf.float32)\n",
    "  obs['image'] = obs['image'] / 255\n",
    "\n",
    "  #resize image to 224 x 224 (can change this later) <-- although, Abayomi-Alli paper showed that there was a plateau of improvement in accuracy when image resolution was >128 pixels for this dataset\n",
    "  obs['image'] = tf.image.resize(obs['image'], (224, 224))\n",
    "\n",
    "  return obs['image'], obs['label']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the above function to the different data splits. Also randomise the dataset to remove any structural bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#apply the above image pre-processing to each data split and randomise dataset\n",
    "training_data = dataset['train'].map(image_preprocessing, num_parallel_calls=AUTOTUNE)\n",
    "validation_data = dataset['validation'].map(image_preprocessing, num_parallel_calls=AUTOTUNE)\n",
    "test_data = dataset['test'].map(image_preprocessing, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that image pre-processing went as expected, let's print an example image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print an example image\n",
    "batch = training_data.as_numpy_iterator()\n",
    "examples = next(iter(batch))\n",
    "plt.imshow(examples['image'])\n",
    "\n",
    "#looks like things went to plan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's define a function that converts images and associated labels to NumPy format for a given data split since this format is needed for the gcForests algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_np_arrays(dataset, split_name, img_size):\n",
    "\n",
    "  #get the number of images in dataset\n",
    "  num_images = len(dataset)\n",
    "\n",
    "  #created empty vectors to populate\n",
    "  x_cassava = np.empty([num_images, img_size, img_size, 3], dtype='float32')\n",
    "  y_cassava = np.empty(num_images, dtype='int64')\n",
    "\n",
    "  #populate the above vectors\n",
    "  counter = 0\n",
    "  for image, label in dataset: \n",
    "    #x_cassava[counter] = data[\"image\"]\n",
    "    #y_cassava[counter] = data[\"label\"]\n",
    "    x_cassava[counter] = image\n",
    "    y_cassava[counter] = label\n",
    "    counter += 1\n",
    "\n",
    "  if counter == num_images:\n",
    "    print('All {} images and labels converted to NumPy arrays'.format(split_name))\n",
    "\n",
    "  return x_cassava, y_cassava"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the above function to the different data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set\n",
    "x_train, y_train = convert_to_np_arrays(dataset = training_data,\n",
    "                                        split_name = 'training',\n",
    "                                        img_size = 224)\n",
    "\n",
    "#check that the shape of the output arrays are correct\n",
    "x_train.shape\n",
    "y_train.shape\n",
    "\n",
    "#save the result\n",
    "np.save('/content/drive/MyDrive/x_train.npy', x_train)\n",
    "np.save('/content/drive/MyDrive/y_train.npy', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation set\n",
    "x_val, y_val = convert_to_np_arrays(dataset = validation_data,\n",
    "                                    split_name = 'validation',\n",
    "                                    img_size = 224)\n",
    "\n",
    "#check the shape\n",
    "x_val.shape\n",
    "y_val.shape\n",
    "\n",
    "#save the result\n",
    "np.save('/content/drive/MyDrive/x_val.npy', x_val)\n",
    "np.save('/content/drive/MyDrive/y_val.npy', y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "x_test, y_test = convert_to_np_arrays(dataset = test_data,\n",
    "                                      split_name = 'test',\n",
    "                                      img_size = 224)\n",
    "\n",
    "#check the shape\n",
    "x_test.shape\n",
    "y_test.shape\n",
    "\n",
    "#save the result\n",
    "np.save('/content/drive/MyDrive/x_test.npy', x_test)\n",
    "np.save('/content/drive/MyDrive/y_test.npy', y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a look at the class distribution within each split to ensure that a stratified split occurred. To begin, let's get the label counts for each of the splits and the overall dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the different label frequencies for each data split\n",
    "train_set_freq = np.unique(y_train, return_counts = True)\n",
    "val_set_freq = np.unique(y_val, return_counts = True)\n",
    "test_set_freq = np.unique(y_test, return_counts = True)\n",
    "\n",
    "#save these in dictionary form\n",
    "\n",
    "#training set\n",
    "train_dict = {}\n",
    "for i in range(5):\n",
    "  train_dict[train_set_freq[0][i]] = train_set_freq[1][i]\n",
    "\n",
    "#validation set\n",
    "val_dict = {}\n",
    "for i in range(5):\n",
    "  val_dict[val_set_freq[0][i]] = val_set_freq[1][i]\n",
    "\n",
    "#test set\n",
    "test_dict = {}\n",
    "for i in range(5):\n",
    "  test_dict[test_set_freq[0][i]] = test_set_freq[1][i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the overall class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to also get an overall count of class labels before split occurred, we will concatenate the class labels and repeat the process\n",
    "dataset_dict = {}\n",
    "dataset_labels = np.concatenate((y_train, y_val, y_test))\n",
    "dataset_labels_freq = np.unique(dataset_labels, return_counts = True)\n",
    "for i in range(5):\n",
    "  dataset_dict[dataset_labels_freq[0][i]] = dataset_labels_freq[1][i]\n",
    "\n",
    "#convert the above dictionaries into Pandas dataframes\n",
    "class_distro_df = pd.DataFrame([dataset_dict])\n",
    "class_distro_df.rename(columns = {0:'CBB', 1:'CBSD', 2:'CGM', 3:'CMD', 4:'Healthy'}, inplace = True)\n",
    "class_distro_df = class_distro_df.transpose()\n",
    "class_distro_df.rename(index = {0:'CBB', 1:'CBSD', 2:'CGM', 3:'CMD', 4:'Healthy'}, columns = {0: 'Frequency'}, inplace = True)\n",
    "\n",
    "#plot the overall class distributions\n",
    "class_distro_plt = class_distro_df.plot(kind='bar', legend=None, rot=0, color='#f08e70')\n",
    "class_distro_plt.set_ylabel(\"Number of images\", labelpad=10)\n",
    "class_distro_plt.set_xlabel(\"Class label\", labelpad=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at the class distribution by data split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_counts = {}\n",
    "freq_counts['training'] = train_dict\n",
    "freq_counts['validation'] = val_dict\n",
    "freq_counts['test'] = test_dict\n",
    "\n",
    "#create dataframe from dictionary\n",
    "df = pd.DataFrame.from_dict(freq_counts)\n",
    "df = df.transpose()\n",
    "df.rename(columns = {0:'CBB', 1:'CBSD', 2:'CGM', 3:'CMD', 4:'Healthy'}, inplace = True)\n",
    "\n",
    "#Plot the results\n",
    "plt = df.plot(kind='bar', rot=0, color={'CBB': '#3ff37e', 'CBSD': '#e1877f', 'CGM': '#f09f70', 'CMD': '#77a6e9', 'Healthy': '#8c81df'})\n",
    "plt.set_ylabel(\"Number of images\", labelpad=10)\n",
    "plt.set_xlabel(\"Data split\", labelpad=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see from the above that a stratified split of the class labels occurred. This helps to reduce the effects of class bias during training, whilst maintaining the distribution of the class labels across all data splits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd12a94ba73b262ab6bf303e44477bea6db1daa26d83ea85081239c32c820f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
